{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db89d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naatural language toolkit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import warnings\n",
    "import sklearn\n",
    "import gensim\n",
    "import json\n",
    "import sys\n",
    "import csv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76f8cfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\nikita uprety\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\nikita uprety\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\nikita uprety\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\nikita uprety\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nikita uprety\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\nikita uprety\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dcb6ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\",context=\"notebook\",palette=\"deep\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46dd9795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Nikita\n",
      "[nltk_data]     Uprety\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Nikita\n",
      "[nltk_data]     Uprety\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Nikita Uprety\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download()\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8034ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is a truth universally acknowledged!, that? a single man in possession of a good fortune, must be in want of a wife.\n"
     ]
    }
   ],
   "source": [
    "text=\"It is a truth universally acknowledged!, that? a single man in possession of a good fortune, must be in want of a wife.\"\n",
    "text=text.lower()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7af17d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "# removing punctuation\n",
    "import string\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1431f0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is a truth universally acknowledged that a single man in possession of a good fortune must be in want of a wife\n"
     ]
    }
   ],
   "source": [
    "text_p = \"\".join([char for char in text if char not in string.punctuation])\n",
    "print(text_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90fd8374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'is', 'a', 'truth', 'universally', 'acknowledged', 'that', 'a', 'single', 'man', 'in', 'possession', 'of', 'a', 'good', 'fortune', 'must', 'be', 'in', 'want', 'of', 'a', 'wife']\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "from nltk import word_tokenize\n",
    "words = word_tokenize(text_p)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba6137ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=stopwords.words(\"english\")\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b963e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['truth', 'universally', 'acknowledged', 'single', 'man', 'possession', 'good', 'fortune', 'must', 'want', 'wife']\n"
     ]
    }
   ],
   "source": [
    "# filter words\n",
    "filtered_words=[word for word in words if word not in stop_words]\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "978dd30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['truth', 'univers', 'acknowledg', 'singl', 'man', 'possess', 'good', 'fortun', 'must', 'want', 'wife']\n"
     ]
    }
   ],
   "source": [
    "# stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter=PorterStemmer()\n",
    "stemmed=[porter.stem(word) for word in filtered_words]\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2043612a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('truth', 'NN'), ('universally', 'RB'), ('acknowledged', 'VBD'), ('single', 'JJ'), ('man', 'NN'), ('possession', 'NN'), ('good', 'JJ'), ('fortune', 'NN'), ('must', 'MD'), ('want', 'VB'), ('wife', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "#part of speech\n",
    "from nltk import pos_tag\n",
    "pos = pos_tag(filtered_words)\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "804c0370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining all together\n",
    "import nltk\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb34c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    text_p = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    \n",
    "    words = word_tokenize(text_p)\n",
    "    \n",
    "    stop_words=stopwords.words(\"english\")\n",
    "    filtered_words=[word for word in words if word not in stop_words]\n",
    "    \n",
    "    porter=PorterStemmer()\n",
    "    stemmed=[porter.stem(word) for word in filtered_words]\n",
    "    \n",
    "    pos = pos_tag(filtered_words)\n",
    "    \n",
    "    return words, filtered_words, stemmed, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d1575d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"Hello, I am nIKita Uprety* why I am writing this oh hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78a739db",
   "metadata": {},
   "outputs": [],
   "source": [
    "words, filtered_words, stemmed, pos = preprocess(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dd62381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'i', 'am', 'nikita', 'uprety', 'why', 'i', 'am', 'writing', 'this', 'oh', 'hello']\n",
      "['hello', 'nikita', 'uprety', 'writing', 'oh', 'hello']\n",
      "['hello', 'nikita', 'upreti', 'write', 'oh', 'hello']\n"
     ]
    }
   ],
   "source": [
    "print(words)\n",
    "print(filtered_words)\n",
    "print(stemmed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
